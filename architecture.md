# Analyse Tech Stack - Assistant IA Supply Chain

## 1. Analyse des Besoins Techniques

### Contraintes Critiques
- **ConfidentialitÃ© maximale** : Purge automatique 24h (data + index vectoriel)
- **Traitement de fichiers complexes** : Excel (accÃ¨s cellule prÃ©cise), PDF, Word, PPT, CSV
- **RAG fiable** : Base vectorielle + embeddings + citations prÃ©cises
- **Chat temps rÃ©el** : Interface fluide type ChatGPT
- **GÃ©nÃ©ration de documents** : Export Word/PDF des rapports
- **Ã‰volutivitÃ©** : MVP â†’ V1 â†’ V2 (simulation, multi-docs)

### Composants Essentiels
1. **Frontend** : Interface chat moderne et responsive
2. **Backend API** : Orchestration + logique mÃ©tier
3. **LLM Gateway** : IntÃ©gration modÃ¨les de langage
4. **RAG Engine** : Vector DB + embeddings + retrieval
5. **Document Parser** : Extraction multi-formats avec mÃ©tadonnÃ©es
6. **Storage** : Temporaire avec TTL automatique
7. **Job Scheduler** : Purge automatique + nettoyage

---

## 2. Comparaison des Options

### Option A : Stack Python Full avec Pinecone/Weaviate

**Architecture**
```
Frontend: Next.js 15 + React + TailwindCSS + shadcn/ui
Backend: FastAPI (Python)
LLM: OpenAI API / Anthropic Claude API
RAG: LangChain + Pinecone/Weaviate (cloud managed)
Document: LangChain Document Loaders + pandas + openpyxl
Storage: PostgreSQL + Redis (TTL)
Scheduling: Celery + Redis
DÃ©ploiement: Docker + AWS/GCP
```

**Avantages**
- âœ… **Ã‰cosystÃ¨me RAG mature** : LangChain est le standard de facto
- âœ… **Traitement Excel avancÃ©** : pandas + openpyxl = accÃ¨s cellule prÃ©cis
- âœ… **BibliothÃ¨ques ML/Data** : numpy, scikit-learn pour analyses avancÃ©es
- âœ… **Document parsing robuste** : PyPDF2, python-docx, python-pptx
- âœ… **Celery** : Job scheduling industriel pour purge automatique
- âœ… **Performance** : FastAPI trÃ¨s rapide (comparable Ã  Node.js)
- âœ… **CommunautÃ© IA** : 90% des outils LLM/RAG sont en Python

**InconvÃ©nients**
- âš ï¸ **Deux langages** : Python backend + TypeScript frontend
- âš ï¸ **Packaging** : Gestion des dÃ©pendances Python parfois complexe
- âš ï¸ **DÃ©ploiement** : NÃ©cessite configuration Python + workers Celery
- âš ï¸ **ConfidentialitÃ©** : Vector DB sur cloud tiers (Pinecone)
- âš ï¸ **TTL externe** : NÃ©cessite Celery pour purge automatique

**CoÃ»t estimÃ© (infra mensuelle MVP)**
- Compute: ~$100-200/mois (API + workers)
- Vector DB: ~$50-100/mois (Pinecone starter)
- LLM API: Variable (~$0.002/1K tokens)
- Total: ~$200-400/mois

---

### Option B : Stack TypeScript Full (DÃ©veloppement Rapide)

**Architecture**
```
Frontend: Next.js 15 + React + TailwindCSS + shadcn/ui
Backend: Next.js API Routes / Hono / tRPC
LLM: Vercel AI SDK / LangChain.js
RAG: LangChain.js + Pinecone/Supabase Vector
Document: xlsx.js + pdf-parse + mammoth
Storage: PostgreSQL + Redis (TTL) ou Supabase
Scheduling: node-cron / BullMQ
DÃ©ploiement: Vercel / Railway / Fly.io
```

**Avantages**
- âœ… **Monorepo simple** : Un seul langage (TypeScript)
- âœ… **DÃ©veloppement rapide** : Code partagÃ© frontend/backend
- âœ… **DX excellent** : Type-safety end-to-end avec tRPC
- âœ… **DÃ©ploiement simplifiÃ©** : Vercel one-click deploy
- âœ… **Edge computing** : PossibilitÃ© de edge functions
- âœ… **Ã‰cosystÃ¨me moderne** : Bun, Deno, Node.js performant

**InconvÃ©nients**
- âš ï¸ **RAG moins mature** : LangChain.js moins riche que Python
- âš ï¸ **Traitement Excel limitÃ©** : xlsx.js moins puissant que pandas
- âš ï¸ **BibliothÃ¨ques data** : Moins d'outils pour analyse avancÃ©e
- âš ï¸ **Citation prÃ©cise Excel** : Plus complexe Ã  implÃ©menter
- âš ï¸ **Job scheduling** : Moins robuste que Celery

**CoÃ»t estimÃ© (infra mensuelle MVP)**
- Compute: ~$50-150/mois (Vercel Pro)
- Vector DB: ~$50-100/mois
- LLM API: Variable
- Total: ~$150-350/mois

---

### Option C : Stack Hybride (Best of Both Worlds)

**Architecture**
```
Frontend: Next.js 15 + React + TailwindCSS
API Gateway: Next.js API Routes (orchestration)
Microservices:
  - RAG Service: FastAPI (Python) - LangChain + vector ops
  - Document Service: FastAPI (Python) - parsing + extraction
  - Export Service: FastAPI (Python) - gÃ©nÃ©ration Word/PDF
LLM: OpenAI/Anthropic API via Python SDK
Vector DB: Pinecone / Weaviate
Storage: Supabase (PostgreSQL + Auth + Storage + TTL)
Scheduling: Supabase Edge Functions + pg_cron
DÃ©ploiement: Vercel (frontend) + Fly.io/Railway (services Python)
```

**Avantages**
- âœ… **Meilleur des deux mondes** : TypeScript UX + Python AI/Data
- âœ… **Services dÃ©couplÃ©s** : ScalabilitÃ© indÃ©pendante
- âœ… **Supabase** : Auth + DB + Storage + Edge Functions tout-en-un
- âœ… **Python pour IA** : Meilleure qualitÃ© RAG + parsing
- âœ… **Frontend optimal** : Next.js best-in-class

**InconvÃ©nients**
- âš ï¸ **ComplexitÃ© architecture** : Multiple services Ã  maintenir
- âš ï¸ **Latence rÃ©seau** : Inter-service communication
- âš ï¸ **CoÃ»t DevOps** : Plus de services = plus de monitoring
- âš ï¸ **Over-engineering pour MVP** : Trop complexe au dÃ©marrage

**CoÃ»t estimÃ© (infra mensuelle MVP)**
- Compute: ~$150-250/mois (Vercel + Fly.io)
- Supabase: ~$25-50/mois
- Vector DB: ~$50-100/mois
- Total: ~$250-450/mois

---

### Option D : Stack Supabase + Edge (Low-Code Pro)

**Architecture**
```
Frontend: Next.js 15 + React + TailwindCSS
Backend: Supabase (PostgreSQL + Auth + Storage + Edge Functions)
RAG: pgvector (extension PostgreSQL) + Supabase Edge Functions
LLM: OpenAI/Anthropic API via Edge Functions
Document: pdf-parse + xlsx dans Edge Functions (limitÃ©)
Scheduling: pg_cron + Supabase Edge Functions
DÃ©ploiement: Vercel + Supabase Cloud
```

**Avantages**
- âœ… **Tout-en-un** : Une seule plateforme (Supabase)
- âœ… **pgvector natif** : Vector store dans PostgreSQL
- âœ… **Row Level Security** : SÃ©curitÃ© granulaire native
- âœ… **TTL automatique** : pg_cron pour purge
- âœ… **CoÃ»t rÃ©duit** : Moins de services
- âœ… **Maintenance minimale** : Plateforme managÃ©e

**InconvÃ©nients**
- âš ï¸ **Edge Functions limitÃ©es** : Timeout 150s max, RAM limitÃ©e
- âš ï¸ **Traitement fichiers lourd** : Pas idÃ©al pour gros Excel/PDF
- âš ï¸ **RAG basique** : Moins sophistiquÃ© que LangChain
- âš ï¸ **Vendor lock-in** : DÃ©pendance Ã  Supabase
- âš ï¸ **GÃ©nÃ©ration documents** : Complexe dans Edge Functions

**CoÃ»t estimÃ© (infra mensuelle MVP)**
- Supabase: ~$25-75/mois (Pro plan)
- Vercel: ~$20-50/mois
- LLM API: Variable
- Total: ~$100-250/mois

---

### Option E : Stack Python Full avec TypeSense ğŸ†• â­ RECOMMANDÃ‰

**Architecture**
```
Frontend: Next.js 15 + React + TailwindCSS + shadcn/ui
Backend: FastAPI (Python)
LLM: OpenAI API / Anthropic Claude API
RAG: LangChain + TypeSense (self-hosted)
Document: pandas + openpyxl + PyPDF2 + python-docx + python-pptx
Storage: PostgreSQL + Redis
Scheduling: Minimal (TypeSense TTL natif)
DÃ©ploiement: Docker + Fly.io/Railway
```

**Avantages**
- âœ… **Tous les avantages de l'Option A** (Python/pandas/LangChain)
- âœ… **ConfidentialitÃ© maximale** : Self-hosted, donnÃ©es ne quittent jamais votre infra
- âœ… **TTL natif** : Purge automatique 24h intÃ©grÃ©e Ã  TypeSense (pas besoin de Celery Beat!)
- âœ… **Recherche hybride** : Keyword + Vector dans la mÃªme requÃªte
  - Parfait pour : "rupture de stock" (sÃ©mantique) + "cellule C12" (exact match)
- âœ… **MÃ©tadonnÃ©es riches** : Filtrage ultra-rapide pour citations prÃ©cises
- âœ… **Performance C++** : Latence <50ms, optimisÃ© pour production
- âœ… **CoÃ»t rÃ©duit** : $0 (self-hosted) vs $70/mois (Pinecone)
- âœ… **SimplicitÃ© architecture** : Moins de composants vs Pinecone+Celery

**InconvÃ©nients**
- âš ï¸ **Deux langages** : Python backend + TypeScript frontend (comme Option A)
- âš ï¸ **IntÃ©gration LangChain** : Moins "plug & play" que Pinecone (mais supportÃ©e)
- âš ï¸ **CommunautÃ© plus petite** : Moins d'exemples que Pinecone (mais docs excellentes)
- âš ï¸ **Self-hosting** : NÃ©cessite gÃ©rer un service supplÃ©mentaire (mais trÃ¨s stable)

**CoÃ»t estimÃ© (infra mensuelle MVP)**
- Compute: ~$50-100/mois (API + TypeSense container)
- PostgreSQL: ~$15-25/mois
- Redis: ~$10-15/mois
- LLM API: Variable (~$50-200/mois selon usage)
- Total: ~$125-340/mois (**30-40% moins cher que Option A**)

**Pourquoi TypeSense pour ce projet spÃ©cifique ?**

1. **ConfidentialitÃ© = contrainte #1 du PRD**
   - Self-hosted : contrÃ´le total des donnÃ©es sensibles Supply Chain
   - Aucune donnÃ©e ne transite vers un cloud tiers

2. **TTL natif = simplifie l'architecture**
   ```python
   # Purge automatique intÃ©grÃ©e !
   typesense_doc = {
       "content": "...",
       "ttl": 86400  # 24h
   }
   ```
   - RÃ©duit complexitÃ© Celery (juste pour jobs mÃ©tier, pas infra)

3. **Recherche hybride = citations Excel prÃ©cises**
   ```python
   # Une seule requÃªte pour sÃ©mantique + exact match
   search = {
       "q": "rupture stock",           # SÃ©mantique
       "filter_by": "cell_ref:=C12",  # Exact match
       "vector_query": "embedding:([...], k:10)"
   }
   ```
   - Pinecone = vector only, filtrage post-requÃªte moins performant

4. **Performance = <50ms latency**
   - Ã‰crit en C++ vs Python indexing
   - Critical pour UX chat temps rÃ©el

---

## 3. Matrice de DÃ©cision

| CritÃ¨re | Option E (Python+TypeSense) ğŸ† | Option A (Python+Pinecone) | Option B (TypeScript) | Option C (Hybride) | Option D (Supabase) |
|---------|------------------------|------------------------|----------------------|-------------------|---------------------|
| **RAG Quality** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **Excel Parsing** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­ |
| **Citations PrÃ©cises** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ |
| **Recherche Hybride** | â­â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­ |
| **TTL/Purge Auto** | â­â­â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Dev Speed** | â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **ScalabilitÃ©** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **CoÃ»t MVP** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **Maintenance** | â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |
| **Time-to-Market** | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­ | â­â­â­â­ |
| **Export Docs** | â­â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­ |
| **ConfidentialitÃ©** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ |
| **Performance** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **SimplicitÃ© Archi** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­â­ |

---

## 4. Recommandation Finale

### ğŸ† **CHOIX RECOMMANDÃ‰ : Option E - Stack Python Full avec TypeSense**

**Justification**

Pour ce projet spÃ©cifique, le **Stack Python + TypeSense** est le choix optimal car il combine :
- Tous les avantages de Python (pandas, LangChain, parsing robuste)
- Les bÃ©nÃ©fices uniques de TypeSense pour vos contraintes mÃ©tier

#### 1. **Contraintes mÃ©tier critiques MIEUX adressÃ©es**
- **Citations prÃ©cises Excel** : `openpyxl` + `pandas` (Python) + recherche hybride TypeSense = prÃ©cision maximale
- **RAG fiable** : LangChain Python mature + recherche hybride keyword/vector
- **ConfidentialitÃ© maximale** : Self-hosted TypeSense = contrÃ´le total (vs Pinecone cloud)
- **GÃ©nÃ©ration documents** : python-docx/reportlab (incontournables)

#### 2. **Architecture simplifiÃ©e vs Pinecone**
- **TTL natif TypeSense** : Purge 24h automatique sans Celery Beat
- **Recherche hybride** : Une requÃªte pour sÃ©mantique + exact match (vs 2 requÃªtes Pinecone)
- **Moins de composants** : Pas de Celery Beat pour purge = moins de maintenance

#### 3. **Avantages TypeSense spÃ©cifiques au use case**

| Besoin PRD | Solution TypeSense | Avantage vs Pinecone |
|------------|-------------------|----------------------|
| "Selon la cellule C12..." | Filtrage exact `cell_ref:=C12` + recherche sÃ©mantique | Pinecone = filtrage post-requÃªte |
| Purge 24h obligatoire | `ttl: 86400` natif | Pinecone = Celery externe requis |
| ConfidentialitÃ© stricte | Self-hosted, donnÃ©es locales | Pinecone = cloud tiers |
| Performance chat | <50ms C++ | Pinecone = >100ms API cloud |
| CoÃ»t | $0-50/mois | Pinecone = $70-100/mois |

#### 4. **Ã‰volutivitÃ© vers V2**
- **Simulation What-if** : pandas dataframes
- **Analyse temporelle** : statsmodels, prophet
- **Formules Supply Chain** : Numpy/Scipy
- **Multi-docs V2** : TypeSense scale horizontalement

#### 5. **Ã‰cosystÃ¨me LLM**
- 95% des exemples/docs LLM sont en Python
- TypeSense supporte LangChain Python
- AccÃ¨s prioritaire aux nouvelles features (OpenAI, Anthropic)

---

## 5. Stack Technique DÃ©taillÃ©e RecommandÃ©e

### Architecture Finale

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FRONTEND                                â”‚
â”‚  Next.js 15 + React 19 + TailwindCSS + shadcn/ui           â”‚
â”‚  - Streaming UI (pour rÃ©ponses LLM)                         â”‚
â”‚  - Upload multi-fichiers                                    â”‚
â”‚  - Historique conversations                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚ HTTP/WebSocket
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    API BACKEND                               â”‚
â”‚  FastAPI (Python 3.11+) + Pydantic v2                       â”‚
â”‚  - Endpoints REST + WebSocket streaming                     â”‚
â”‚  - Authentification JWT                                      â”‚
â”‚  - Rate limiting                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                    â”‚                    â”‚
          â–¼                    â–¼                    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  RAG ENGINE      â”‚  â”‚ DOCUMENT PARSER   â”‚  â”‚  EXPORT SERVICE  â”‚
â”‚  LangChain       â”‚  â”‚  - openpyxl       â”‚  â”‚  - python-docx   â”‚
â”‚  - OpenAI        â”‚  â”‚  - pandas         â”‚  â”‚  - reportlab     â”‚
â”‚  - Embeddings    â”‚  â”‚  - PyPDF2         â”‚  â”‚  - jinja2        â”‚
â”‚  - Citations     â”‚  â”‚  - python-docx    â”‚  â”‚                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚
          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  VECTOR DATABASE                             â”‚
â”‚  TypeSense (self-hosted) - Recherche Hybride                â”‚
â”‚  - Keyword + Vector search simultanÃ©s                       â”‚
â”‚  - Metadata filtering (filename, cell_ref, sheet_name)      â”‚
â”‚  - TTL natif (86400s = 24h auto-delete)                    â”‚
â”‚  - Performance C++ (<50ms latency)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     STORAGE LAYER                            â”‚
â”‚  PostgreSQL (donnÃ©es mÃ©tier) + Redis (cache/queue)          â”‚
â”‚  - Conversations + metadata                                  â”‚
â”‚  - TTL automatique (pg_cron)                                â”‚
â”‚  - MinIO/S3 pour fichiers temporaires (24h)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   JOB SCHEDULER (SimplifiÃ©)                  â”‚
â”‚  Celery + Redis (jobs mÃ©tier uniquement)                   â”‚
â”‚  - GÃ©nÃ©ration rapports async                                â”‚
â”‚  - Monitoring santÃ© systÃ¨me                                 â”‚
â”‚  Note: Purge 24h gÃ©rÃ©e nativement par TypeSense TTL!       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technologies SpÃ©cifiques

#### Frontend
```json
{
  "framework": "Next.js 15",
  "ui": "shadcn/ui + TailwindCSS",
  "chat": "@vercel/ai (streaming)",
  "upload": "react-dropzone",
  "state": "Zustand",
  "forms": "React Hook Form + Zod"
}
```

#### Backend
```python
# pyproject.toml
[tool.poetry.dependencies]
python = "^3.11"
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
pydantic = "^2.5.0"

# RAG & LLM
langchain = "^0.1.0"
langchain-openai = "^0.0.5"
langchain-anthropic = "^0.1.0"
typesense = "^0.17.0"           # TypeSense client
langchain-community = "^0.0.16" # Pour TypeSense vectorstore

# Document Processing
openpyxl = "^3.1.2"         # Excel read/write avec accÃ¨s cellule
pandas = "^2.2.0"           # Analyse donnÃ©es
PyPDF2 = "^3.0.1"          # PDF parsing
python-docx = "^1.1.0"     # Word read/write
python-pptx = "^0.6.23"    # PowerPoint read
reportlab = "^4.0.9"       # PDF generation

# Storage & Cache
psycopg2-binary = "^2.9.9"
redis = "^5.0.1"
sqlalchemy = "^2.0.25"

# Task Queue
celery = {extras = ["redis"], version = "^5.3.6"}

# Security
python-jose = {extras = ["cryptography"], version = "^3.3.0"}
passlib = {extras = ["bcrypt"], version = "^1.7.4"}
```

#### Infrastructure
```yaml
# docker-compose.yml structure
services:
  api:          # FastAPI
  frontend:     # Next.js
  typesense:    # Vector + Keyword search (TTL natif) ğŸ†•
  postgres:     # Database
  redis:        # Cache + Celery broker
  celery:       # Worker (jobs mÃ©tier uniquement)
  minio:        # S3-compatible storage (dev)
  # Note: celery-beat optionnel (TypeSense gÃ¨re purge 24h!)
```

#### Configuration TypeSense
```yaml
# docker-compose.yml - TypeSense service
typesense:
  image: typesense/typesense:27.0
  ports:
    - "8108:8108"
  volumes:
    - ./typesense-data:/data
  environment:
    - TYPESENSE_DATA_DIR=/data
    - TYPESENSE_API_KEY=${TYPESENSE_API_KEY}
    - TYPESENSE_ENABLE_CORS=true
  command: '--data-dir /data --api-key=${TYPESENSE_API_KEY}'
```

---

## 6. Plan de Migration Progressive

### Phase MVP (Semaines 1-6)
```
Week 1-2: Setup infra + Auth
  - Docker compose local
  - FastAPI boilerplate + Next.js
  - PostgreSQL + Redis
  - Auth JWT basique

Week 3-4: RAG Core + Upload
  - LangChain setup
  - TypeSense setup (Docker local)
  - Upload Excel/PDF/CSV
  - Document chunking + embeddings
  - Schema TypeSense avec TTL

Week 5: Chat + Citations
  - WebSocket streaming
  - Citation tracking
  - Metadata extraction (cell refs)

Week 6: Polish & Tests
  - Validation TTL TypeSense (purge 24h)
  - Tests citations Excel prÃ©cises
  - UI/UX finitions
  - (Celery Beat optionnel pour monitoring)
```

### Risques & Mitigation

| Risque | Impact | Mitigation |
|--------|--------|------------|
| Citation Excel imprÃ©cise | CRITIQUE | Tests unitaires sur openpyxl + pandas |
| Hallucinations LLM | CRITIQUE | RAG strict + tempÃ©rature 0.1 + citations obligatoires |
| CoÃ»t API LLM | MOYEN | Cache embeddings + rÃ©ponses similaires (Redis) |
| Latence upload gros fichiers | MOYEN | Streaming upload + workers async |
| Purge manquÃ©e | CRITIQUE | TypeSense TTL natif + monitoring alerting + pg_cron backup |

---

## 7. Alternatives Quick-Start (Si contraintes temps/budget)

### Si besoin MVP en 2 semaines max :
**Option B (TypeScript Full)** devient valide avec compromis :
- Utiliser `exceljs` au lieu de pandas
- RAG simplifiÃ© avec LangChain.js
- Accepter moins de prÃ©cision sur citations Excel Phase 1
- Migrer vers Python pour Phase 2

### Si budget trÃ¨s limitÃ© (<$100/mois) :
**Option D (Supabase)** avec :
- pgvector pour RAG basique
- Edge Functions pour parsing lÃ©ger
- Accepter limitations fichiers volumineux
- Upgrade infrastructure en V1

---

## 8. TypeSense vs Alternatives : Comparaison DÃ©taillÃ©e

| CritÃ¨re | TypeSense (RecommandÃ©) | Pinecone | Weaviate | pgvector (Supabase) |
|---------|------------------------|----------|----------|---------------------|
| **Self-hosted** | âœ… Facile | âŒ Cloud only | âœ… Complexe | âœ… Via Postgres |
| **TTL natif** | âœ… 86400s | âŒ Manuel | âš ï¸ Partiel | âœ… pg_cron |
| **Recherche hybride** | âœ… Keyword+Vector | âŒ Vector only | âœ… | âš ï¸ Basique |
| **Performance** | â­â­â­â­â­ (<50ms) | â­â­â­â­ (100ms) | â­â­â­â­ | â­â­â­ |
| **CoÃ»t MVP** | $0-50/mois | $70-100/mois | $30-80/mois | $25-50/mois |
| **IntÃ©gration LangChain** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­ |
| **Filtrage metadata** | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ |
| **ConfidentialitÃ©** | â­â­â­â­â­ | â­â­â­ | â­â­â­â­â­ | â­â­â­â­â­ |
| **Maintenance** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­ | â­â­â­â­ |
| **Documentation** | â­â­â­â­ | â­â­â­â­â­ | â­â­â­â­ | â­â­â­â­ |

### Pourquoi TypeSense gagne pour ce projet ?

#### ScÃ©nario typique : Citation Excel prÃ©cise

**Besoin utilisateur** : "Montre-moi les ruptures de stock mentionnÃ©es dans production.xlsx"

**Avec TypeSense (1 requÃªte)** :
```python
search = {
    "q": "rupture stock",              # Recherche sÃ©mantique
    "query_by": "content",
    "filter_by": "filename:=production.xlsx AND sheet_name:=Stocks",
    "vector_query": "embedding:([...], k:10)",
    "facet_by": "cell_ref"            # AgrÃ©gation par cellule
}
# RÃ©sultat : "Selon cellule C12 de production.xlsx..."
# Latence : 35ms
```

**Avec Pinecone (2+ requÃªtes)** :
```python
# 1. Vector search
results = index.query(vector=[...], top_k=100, include_metadata=True)
# 2. Post-filtrage Python
filtered = [r for r in results if r.metadata['filename'] == 'production.xlsx']
# 3. Keyword search sÃ©parÃ© pour "cellule C12"
# RÃ©sultat : MÃªme info mais moins prÃ©cis
# Latence : 120ms + filtrage
```

**TypeSense = 3x plus rapide + plus prÃ©cis + moins de code**

---

## 9. Exemple d'ImplÃ©mentation TypeSense

### Setup Collection avec TTL

```python
from langchain_community.vectorstores import Typesense
from langchain.embeddings import OpenAIEmbeddings
import typesense

# Client TypeSense
client = typesense.Client({
    'nodes': [{'host': 'localhost', 'port': '8108', 'protocol': 'http'}],
    'api_key': os.getenv('TYPESENSE_API_KEY'),
    'connection_timeout_seconds': 2
})

# Schema avec TTL + mÃ©tadonnÃ©es riches
schema = {
    'name': 'supply_chain_documents',
    'fields': [
        # Contenu
        {'name': 'content', 'type': 'string'},
        {'name': 'embedding', 'type': 'float[]', 'num_dim': 1536},

        # MÃ©tadonnÃ©es Excel
        {'name': 'filename', 'type': 'string', 'facet': True},
        {'name': 'cell_ref', 'type': 'string', 'optional': True, 'facet': True},
        {'name': 'sheet_name', 'type': 'string', 'optional': True, 'facet': True},
        {'name': 'row', 'type': 'int32', 'optional': True},
        {'name': 'column', 'type': 'string', 'optional': True},

        # Contexte mÃ©tier
        {'name': 'doc_type', 'type': 'string', 'facet': True},  # "excel", "pdf", "csv"
        {'name': 'user_id', 'type': 'string', 'facet': True},
        {'name': 'conversation_id', 'type': 'string', 'facet': True},

        # Timestamps
        {'name': 'upload_timestamp', 'type': 'int64'},
        {'name': 'created_at', 'type': 'int64', 'sort': True},
    ],
    'default_sorting_field': 'created_at',
    'token_separators': [',', '.', ':', ';'],

    # ğŸ”¥ TTL NATIF - Purge automatique 24h !
    'metadata': {
        'ttl': 86400  # secondes
    }
}

client.collections.create(schema)
```

### Indexation Document Excel

```python
import pandas as pd
import openpyxl
from datetime import datetime

def index_excel_to_typesense(filepath: str, user_id: str, conv_id: str):
    """Parse Excel et indexe avec mÃ©tadonnÃ©es cellule par cellule"""

    wb = openpyxl.load_workbook(filepath)
    embeddings = OpenAIEmbeddings()

    documents = []

    for sheet_name in wb.sheetnames:
        sheet = wb[sheet_name]
        df = pd.read_excel(filepath, sheet_name=sheet_name)

        # Indexer chaque cellule avec valeur significative
        for row_idx, row in df.iterrows():
            for col_name, value in row.items():
                if pd.notna(value) and str(value).strip():

                    # Contexte : cellule + voisines
                    context = f"{col_name}: {value}"
                    if row_idx > 0:
                        context += f" (ligne prÃ©cÃ©dente: {df.iloc[row_idx-1][col_name]})"

                    # Embedding
                    vector = embeddings.embed_query(context)

                    # Document TypeSense
                    doc = {
                        'content': context,
                        'embedding': vector,
                        'filename': os.path.basename(filepath),
                        'sheet_name': sheet_name,
                        'cell_ref': f"{col_name}{row_idx+2}",  # Excel row (1-indexed + header)
                        'row': int(row_idx + 2),
                        'column': col_name,
                        'doc_type': 'excel',
                        'user_id': user_id,
                        'conversation_id': conv_id,
                        'upload_timestamp': int(datetime.now().timestamp()),
                        'created_at': int(datetime.now().timestamp()),
                    }

                    documents.append(doc)

    # Bulk insert
    client.collections['supply_chain_documents'].documents.import_(documents)

    return len(documents)
```

### RequÃªte Hybride avec Citations

```python
def search_with_citations(query: str, conv_id: str, top_k: int = 5):
    """Recherche hybride keyword+vector avec citations Excel prÃ©cises"""

    # Embedding query
    query_vector = embeddings.embed_query(query)

    # Recherche hybride TypeSense
    search_params = {
        'q': query,
        'query_by': 'content',
        'filter_by': f'conversation_id:={conv_id}',
        'vector_query': f'embedding:({query_vector}, k:{top_k})',
        'include_fields': 'content,filename,cell_ref,sheet_name,row,column',
        'per_page': top_k,
        'facet_by': 'filename,sheet_name',
    }

    results = client.collections['supply_chain_documents'].documents.search(search_params)

    # Formatter rÃ©sultats avec citations
    citations = []
    for hit in results['hits']:
        doc = hit['document']
        citation = {
            'content': doc['content'],
            'source': f"Selon la cellule {doc['cell_ref']} (feuille '{doc['sheet_name']}' du fichier {doc['filename']})",
            'metadata': {
                'file': doc['filename'],
                'sheet': doc['sheet_name'],
                'cell': doc['cell_ref'],
                'row': doc.get('row'),
                'column': doc.get('column'),
            }
        }
        citations.append(citation)

    return citations

# Utilisation
results = search_with_citations("ruptures de stock", conv_id="abc123")
# Output: "Selon la cellule C12 (feuille 'Stocks' du fichier production.xlsx):
#          Stock nÃ©gatif dÃ©tectÃ© : -150 unitÃ©s"
```

---

## 10. Conclusion

Le **Stack Python + TypeSense (Option E)** est le choix techniquement optimal pour ce projet car :

1. âœ… **FiabilitÃ© maximum** : Python/LangChain/pandas pour Ã©viter hallucinations
2. âœ… **Citations Excel prÃ©cises** : Recherche hybride + mÃ©tadonnÃ©es riches
3. âœ… **ConfidentialitÃ© maximale** : Self-hosted, argument commercial fort
4. âœ… **TTL natif** : Simplifie architecture (moins de Celery)
5. âœ… **Performance** : <50ms latency, critical pour UX chat
6. âœ… **CoÃ»t rÃ©duit** : 30-40% moins cher que Pinecone
7. âœ… **Ã‰volutivitÃ© V2** : Simulation, calculs avancÃ©s avec Python

**Trade-off acceptÃ©** : 2-3 semaines de dev vs TypeScript, mais qualitÃ©/robustesse/confidentialitÃ© justifient largement ce dÃ©lai pour un produit B2B Supply Chain oÃ¹ la fiabilitÃ© est critique.

**ComparÃ© Ã  Pinecone** : TypeSense apporte recherche hybride, TTL natif, self-hosting et coÃ»t rÃ©duit - tous critiques pour vos contraintes PRD.

**Next Step** :
1. **POC 3 jours** : FastAPI + TypeSense + openpyxl + LangChain
2. **Validation** : Parser Excel â†’ Indexer avec TTL â†’ RequÃªte hybride â†’ Citation prÃ©cise
3. **Go/No-Go** : Si POC OK â†’ dÃ©veloppement MVP complet
